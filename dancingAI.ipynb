{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dancingAI.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajit2704/dancingAI/blob/master/dancingAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "M7LQ-kZtEVFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "os.symlink('/gdrive/My Drive', '/content/gdrive')\n",
        "!ls -l /content/gdrive/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IaSB64MAFZ9G",
        "colab_type": "code",
        "outputId": "15f23d43-fa21-4bca-ff89-7ad487ae2d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers import Dense\n",
        "from keras.engine.topology import Layer\n",
        "import numpy as np\n",
        "from tensorflow.contrib.distributions import Categorical, Mixture, MultivariateNormalDiag\n",
        "import tensorflow as tf\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Input\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import Lambda\n",
        "from keras.models import Model\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "def elu_plus_one_plus_epsilon(x):\n",
        "    \"\"\"ELU activation with a very small addition to help prevent NaN in loss.\"\"\"\n",
        "    return (K.elu(x) + 1 + 1e-8)\n",
        "\n",
        "\n",
        "class MDN(Layer):\n",
        "    \"\"\"A Mixture Density Network Layer for Keras.\n",
        "    This layer has a few tricks to avoid NaNs in the loss function when training:\n",
        "        - Activation for variances is ELU + 1 + 1e-8 (to avoid very small values)\n",
        "        - Mixture weights (pi) are trained in as logits, not in the softmax space.\n",
        "\n",
        "    A loss function needs to be constructed with the same output dimension and number of mixtures.\n",
        "    A sampling function is also provided to sample from distribution parametrised by the MDN outputs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_dimension, num_mixtures, **kwargs):\n",
        "        self.output_dim = output_dimension\n",
        "        self.num_mix = num_mixtures\n",
        "        with tf.name_scope('MDN'):\n",
        "            self.mdn_mus = Dense(self.num_mix * self.output_dim, name='mdn_mus')  # mix*output vals, no activation\n",
        "            self.mdn_sigmas = Dense(self.num_mix * self.output_dim, activation=elu_plus_one_plus_epsilon, name='mdn_sigmas')  # mix*output vals exp activation\n",
        "            self.mdn_pi = Dense(self.num_mix, name='mdn_pi')  # mix vals, logits\n",
        "        super(MDN, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.mdn_mus.build(input_shape)\n",
        "        self.mdn_sigmas.build(input_shape)\n",
        "        self.mdn_pi.build(input_shape)\n",
        "        self.trainable_weights = self.mdn_mus.trainable_weights + self.mdn_sigmas.trainable_weights + self.mdn_pi.trainable_weights\n",
        "        self.non_trainable_weights = self.mdn_mus.non_trainable_weights + self.mdn_sigmas.non_trainable_weights + self.mdn_pi.non_trainable_weights\n",
        "        super(MDN, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        with tf.name_scope('MDN'):\n",
        "            mdn_out = keras.layers.concatenate([self.mdn_mus(x),\n",
        "                                                self.mdn_sigmas(x),\n",
        "                                                self.mdn_pi(x)],\n",
        "                                               name='mdn_outputs')\n",
        "        return mdn_out\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.output_dim)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"output_dimension\": self.output_dim,\n",
        "            \"num_mixtures\": self.num_mix\n",
        "        }\n",
        "        base_config = super(MDN, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "def get_mixture_loss_func(output_dim, num_mixes):\n",
        "    \"\"\"Construct a loss functions for the MDN layer parametrised by number of mixtures.\"\"\"\n",
        "    # Construct a loss function with the right number of mixtures and outputs\n",
        "    def loss_func(y_true, y_pred):\n",
        "        out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[num_mixes * output_dim,\n",
        "                                                                         num_mixes * output_dim,\n",
        "                                                                         num_mixes],\n",
        "                                             axis=1, name='mdn_coef_split')\n",
        "        cat = Categorical(logits=out_pi)\n",
        "        component_splits = [output_dim] * num_mixes\n",
        "        mus = tf.split(out_mu, num_or_size_splits=component_splits, axis=1)\n",
        "        sigs = tf.split(out_sigma, num_or_size_splits=component_splits, axis=1)\n",
        "        coll = [MultivariateNormalDiag(loc=loc, scale_diag=scale) for loc, scale\n",
        "                in zip(mus, sigs)]\n",
        "        mixture = Mixture(cat=cat, components=coll)\n",
        "        loss = mixture.log_prob(y_true)\n",
        "        loss = tf.negative(loss)\n",
        "        loss = tf.reduce_mean(loss)\n",
        "        return loss\n",
        "\n",
        "    # Actually return the loss_func\n",
        "    with tf.name_scope('MDN'):\n",
        "        return loss_func\n",
        "\n",
        "\n",
        "def get_mixture_sampling_fun(output_dim, num_mixes):\n",
        "    \"\"\"Construct a sampling function for the MDN layer parametrised by mixtures and output dimension.\"\"\"\n",
        "    # Construct a loss function with the right number of mixtures and outputs\n",
        "    def sampling_func(y_pred):\n",
        "        out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[num_mixes * output_dim,\n",
        "                                                                         num_mixes * output_dim,\n",
        "                                                                         num_mixes],\n",
        "                                             axis=1, name='mdn_coef_split')\n",
        "        cat = Categorical(logits=out_pi)\n",
        "        component_splits = [output_dim] * num_mixes\n",
        "        mus = tf.split(out_mu, num_or_size_splits=component_splits, axis=1)\n",
        "        sigs = tf.split(out_sigma, num_or_size_splits=component_splits, axis=1)\n",
        "        coll = [MultivariateNormalDiag(loc=loc, scale_diag=scale) for loc, scale\n",
        "                in zip(mus, sigs)]\n",
        "        mixture = Mixture(cat=cat, components=coll)\n",
        "        samp = mixture.sample()\n",
        "        # Todo: temperature adjustment for sampling function.\n",
        "        return samp\n",
        "\n",
        "    # Actually return the loss_func\n",
        "    with tf.name_scope('MDNLayer'):\n",
        "        return sampling_func\n",
        "\n",
        "\n",
        "def get_mixture_mse_accuracy(output_dim, num_mixes):\n",
        "    \"\"\"Construct an MSE accuracy function for the MDN layer\n",
        "    that takes one sample and compares to the true value.\"\"\"\n",
        "    # Construct a loss function with the right number of mixtures and outputs\n",
        "    def mse_func(y_true, y_pred):\n",
        "        out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[num_mixes * output_dim,\n",
        "                                                                         num_mixes * output_dim,\n",
        "                                                                         num_mixes],\n",
        "                                             axis=1, name='mdn_coef_split')\n",
        "        cat = Categorical(logits=out_pi)\n",
        "        component_splits = [output_dim] * num_mixes\n",
        "        mus = tf.split(out_mu, num_or_size_splits=component_splits, axis=1)\n",
        "        sigs = tf.split(out_sigma, num_or_size_splits=component_splits, axis=1)\n",
        "        coll = [MultivariateNormalDiag(loc=loc, scale_diag=scale) for loc, scale\n",
        "                in zip(mus, sigs)]\n",
        "        mixture = Mixture(cat=cat, components=coll)\n",
        "        samp = mixture.sample()\n",
        "        mse = tf.reduce_mean(tf.square(samp - y_true), axis=-1)\n",
        "        # Todo: temperature adjustment for sampling functon.\n",
        "        return mse\n",
        "\n",
        "    # Actually return the loss_func\n",
        "    with tf.name_scope('MDNLayer'):\n",
        "        return mse_func\n",
        "\n",
        "\n",
        "def split_mixture_params(params, output_dim, num_mixes):\n",
        "    \"\"\"Splits up an array of mixture parameters into mus, sigmas, and pis\n",
        "    depending on the number of mixtures and output dimension.\"\"\"\n",
        "    mus = params[:num_mixes*output_dim]\n",
        "    sigs = params[num_mixes*output_dim:2*num_mixes*output_dim]\n",
        "    pi_logits = params[-num_mixes:]\n",
        "    return mus, sigs, pi_logits\n",
        "\n",
        "\n",
        "def softmax(w, t=1.0):\n",
        "    \"\"\"Softmax function for a list or numpy array of logits. Also adjusts temperature.\"\"\"\n",
        "    e = np.array(w) / t  # adjust temperature\n",
        "    e -= e.max()  # subtract max to protect from exploding exp values.\n",
        "    e = np.exp(e)\n",
        "    dist = e / np.sum(e)\n",
        "    return dist\n",
        "\n",
        "\n",
        "def sample_from_categorical(dist):\n",
        "    \"\"\"Samples from a categorical model PDF.\"\"\"\n",
        "    r = np.random.rand(1)  # uniform random number in [0,1]\n",
        "    accumulate = 0\n",
        "    for i in range(0, dist.size):\n",
        "        accumulate += dist[i]\n",
        "        if accumulate >= r:\n",
        "            return i\n",
        "    tf.logging.info('Error sampling mixture model.')\n",
        "    return -1\n",
        "\n",
        "\n",
        "def sample_from_output(params, output_dim, num_mixes, temp=1.0):\n",
        "    \"\"\"Sample from an MDN output with temperature adjustment.\"\"\"\n",
        "    mus = params[:num_mixes*output_dim]\n",
        "    sigs = params[num_mixes*output_dim:2*num_mixes*output_dim]\n",
        "    pis = softmax(params[-num_mixes:], t=temp)\n",
        "    m = sample_from_categorical(pis)\n",
        "    # Alternative way to sample from categorical:\n",
        "    # m = np.random.choice(range(len(pis)), p=pis)\n",
        "    mus_vector = mus[m*output_dim:(m+1)*output_dim]\n",
        "    sig_vector = sigs[m*output_dim:(m+1)*output_dim] * temp  # adjust for temperature\n",
        "    cov_matrix = np.identity(output_dim) * sig_vector\n",
        "    sample = np.random.multivariate_normal(mus_vector, cov_matrix, 1)\n",
        "    return sample"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "oQ92CH8_GS6C",
        "colab_type": "code",
        "outputId": "68e18279-0ec8-4e0f-a3cd-d8ec3bd7aae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "latent_dim = 128\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    # by default, random_normal has mean=0 and std=1.0\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "input_img = Input(shape=(120,208,1))\n",
        "x = Conv2D(filters=128,kernel_size=3, activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D(pool_size=2)(x)\n",
        "x = Conv2D(filters=64,kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=2)(x)\n",
        "x = Conv2D(filters=32,kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=2)(x)\n",
        "shape = K.int_shape(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128,kernel_initializer='glorot_uniform')(x)\n",
        "\n",
        "z_mean = Dense(latent_dim)(x)\n",
        "z_log_var = Dense(latent_dim)(x)\n",
        "z = Lambda(sampling, output_shape=(latent_dim,), name=\"z\")([z_mean,z_log_var])\n",
        "\n",
        "encoder = Model(input_img, [z_mean, z_log_var,z], name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "\n",
        "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = Dense(shape[1] * shape[2] * shape[3], kernel_initializer='glorot_uniform',activation='relu')(latent_inputs)\n",
        "x = Reshape((shape[1],shape[2],shape[3]))(x)\n",
        "x = Dense(128,kernel_initializer='glorot_uniform')(x)\n",
        "x = Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = UpSampling2D(size=(2,2))(x)\n",
        "x = Conv2D(filters=64,kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = UpSampling2D(size=(2,2))(x)\n",
        "x = Conv2D(filters=128,kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = UpSampling2D(size=(2,2))(x)\n",
        "x = Conv2D(filters=1,kernel_size=3, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "decoder = Model(latent_inputs,x,name='decoder')\n",
        "\n",
        "decoder.summary()\n",
        "\n",
        "\n",
        "outputs = decoder(encoder(input_img)[2])\n",
        "print(outputs.shape)\n",
        "vae = Model(input_img,outputs,name=\"vae\")\n",
        "\n",
        "def data_generator(batch_size,limit):\n",
        "\n",
        "\tbatch = []\n",
        "\tcounter = 1\n",
        "\twhile 1:\n",
        "\t\tfor i in range(1,limit+1):\n",
        "\t\t\tif counter >= limit:\n",
        "\t\t\t\tcounter = 1\n",
        "\t\t\timg = cv2.imread(\"imgs/{}.jpg\".format(counter),cv2.IMREAD_GRAYSCALE)\n",
        "\t\t\timg = img.reshape(120,208,1)\n",
        "\t\t\tbatch.append(img)\n",
        "\t\t\tif len(batch) == batch_size:\n",
        "\t\t\t\tbatch_np = np.array(batch) / 255\n",
        "\t\t\t\tbatch = []\n",
        "\t\t\t\tyield (batch_np,None)\n",
        "\t\t\tcounter += 1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 120, 208, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 120, 208, 128 1280        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 60, 104, 128) 0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 60, 104, 64)  73792       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 30, 52, 64)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 30, 52, 32)   18464       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 15, 26, 32)   0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 12480)        0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 128)          1597568     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 128)          16512       dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 128)          16512       dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z (Lambda)                      (None, 128)          0           dense_7[0][0]                    \n",
            "                                                                 dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,724,128\n",
            "Trainable params: 1,724,128\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 12480)             1609920   \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 15, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 15, 26, 128)       4224      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 15, 26, 32)        36896     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 30, 52, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 30, 52, 64)        18496     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 60, 104, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 60, 104, 128)      73856     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 120, 208, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 120, 208, 1)       1153      \n",
            "=================================================================\n",
            "Total params: 1,744,545\n",
            "Trainable params: 1,744,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(?, 120, 208, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4O34JV9hGEHt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BCLB3Qa8ER01",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set paths"
      ]
    },
    {
      "metadata": {
        "id": "Q_wXjG-kER02",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = '/content/gdrive/Colab/src/dancenet-master/d.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "KMCe_hqOER07",
        "colab_type": "code",
        "outputId": "6dff9648-0551-4cda-c87b-0a013847e650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data = np.load('/content/gdrive/Colab/src/dancenet-master/video.npy')\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20210, 1, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HVY7XhS_ER1A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = np.array(data).reshape(-1,128)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler = scaler.fit(data)\n",
        "data =  scaler.transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BvH17EetER1E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "numComponents = 24\n",
        "outputDim = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "Nye2P4XxER1J",
        "colab_type": "code",
        "outputId": "74b706ef-ff3e-4e5d-994b-ce21ef48b2aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(128,))\n",
        "x = Reshape((1,128))(inputs)\n",
        "x = LSTM(512, return_sequences=True,input_shape=(1,128))(x)\n",
        "x = Dropout(0.40)(x)\n",
        "x = LSTM(512, return_sequences=True)(x)\n",
        "x = Dropout(0.40)(x)\n",
        "x = LSTM(512)(x)\n",
        "x = Dropout(0.40)(x)\n",
        "x = Dense(1000,activation='relu')(x)\n",
        "outputs = MDN(outputDim, numComponents)(x)\n",
        "model = Model(inputs=inputs,outputs=outputs)\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1, 512)            1312768   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 512)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 1, 512)            2099200   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 512)            0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1000)              513000    \n",
            "_________________________________________________________________\n",
            "mdn_1 (MDN)                  (None, 128)               6174168   \n",
            "=================================================================\n",
            "Total params: 12,198,336\n",
            "Trainable params: 12,198,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3nRHJyovER1M",
        "colab_type": "code",
        "outputId": "f2d6ef39-3193-4189-c2bc-f18145f91226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "opt = adam(lr=0.0005)\n",
        "model.compile(loss=get_mixture_loss_func(outputDim,numComponents),optimizer=opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-12e0a4c0883a>:74: MultivariateNormalDiag.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_diag) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/mvn_diag.py:224: MultivariateNormalLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.mvn_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/mvn_linear_operator.py:201: AffineLinearOperator.__init__ (from tensorflow.contrib.distributions.python.ops.bijectors.affine_linear_operator) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/affine_linear_operator.py:158: _DistributionShape.__init__ (from tensorflow.contrib.distributions.python.ops.shape) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n",
            "WARNING:tensorflow:From <ipython-input-2-12e0a4c0883a>:76: Mixture.__init__ (from tensorflow.contrib.distributions.python.ops.mixture) is deprecated and will be removed after 2018-10-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.contrib.distributions`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "kJiyyzBxER1R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = False #change to True to train from scratch\n",
        "\n",
        "if train:\n",
        "    X = data[0:len(data)-1]\n",
        "    Y = data[1:len(data)]\n",
        "    checkpoint = ModelCheckpoint(PATH, monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
        "    callbacks_list = [checkpoint]\n",
        "    model.fit(X,Y,batch_size=1024, verbose=1, shuffle=False, validation_split=0.20, epochs=10000, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QE3oDVatER1V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load weights"
      ]
    },
    {
      "metadata": {
        "id": "BoP7JCDHER1X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vae.load_weights('/content/gdrive/Colab/src/dancenet-master/vae.h5')\n",
        "model.load_weights(PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lPBJsAkvER1b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generate Video"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "CnqpygUVER1d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "video = cv2.VideoWriter(\"/content/gdrive/Colab/src/dancenet-master/result.mp4\", z, 30.0, (208, 120))\n",
        "lv_in = data[0]\n",
        "\n",
        "for i in range(500):\n",
        "    input = np.array(y).reshape(1,128)\n",
        "    result = model.predict(input)\n",
        "    shape = np.array(result).shape[1]\n",
        "    result = np.array(result).reshape(shape)\n",
        "    result = sample_from_output(result,128,numComponents,temp=0.01)\n",
        "    result = scaler.inverse_transform(result)\n",
        "    img = decoder.predict(np.array(result).reshape(1,128))\n",
        "    img = np.array(img).reshape(120,208,1)\n",
        "    img = img * 255\n",
        "    img = np.array(img).astype(\"uint8\")\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
        "    y = result\n",
        "    video.write(img)\n",
        "video.release()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5kxoeoGPHgbs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}